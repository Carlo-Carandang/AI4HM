{
 "metadata": {
  "name": "",
  "signature": "sha256:932eedd54a568eed49f1c9f61eeba2b3bf63d548737af52e1ac4a0932c05d33b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setup our standard computation environment\n",
      "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
      "%matplotlib inline\n",
      "sns.set_style('darkgrid')\n",
      "sns.set_context('poster')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set random seed for reproducibility\n",
      "np.random.seed(12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the decision tree module of sklearn\n",
      "import sklearn.tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# simulate some data from a familiar distribution\n",
      "x_true = np.linspace(0,15,1000)\n",
      "y_true = np.cos(x_true)\n",
      "\n",
      "sigma_true = .3\n",
      "x_train = np.random.choice(x_true, size=100)\n",
      "y_train = np.random.laplace(np.cos(x_train), sigma_true)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x_true, y_true, '-', label='Truth')\n",
      "plt.plot(x_train, y_train, 's', label='Train')\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a DecisionTreeRegressor\n",
      "dt = ________________________"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit it to the simulated training data\n",
      "X_train = x_train[:,None]\n",
      "dt.fit(________________________, ________________________)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict for a range of x values\n",
      "X_true = x_true[:,None]\n",
      "y_pred = dt.predict(________________________)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# have a look\n",
      "plt.plot(x_true, y_true, '-', label='Truth')\n",
      "plt.plot(x_train, y_train, 's', label='Train')\n",
      "plt.plot(x_true, y_pred, '-', label='Predicted')\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# today we are going to look in-depth at the decision tree itself\n",
      "\n",
      "# can you find it?\n",
      "dt.________________________"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# what do the sklearn docs have to say about this?\n",
      "help(dt.tree_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take a look at each of these things...  guess what each will return before you execute the cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.node_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.capacity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.max_depth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.children_left"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.children_right"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.feature"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.threshold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.impurity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.n_node_samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.tree_.weighted_n_node_samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how can min samples help?\n",
      "dt = sklearn.tree.DecisionTreeRegressor(min_samples_leaf=10)\n",
      "dt.fit(X_train, y_train)\n",
      "y_pred = dt.predict(X_true)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x_true, y_true, '-', label='Truth')\n",
      "plt.plot(x_train, y_train, 's', label='Train')\n",
      "plt.plot(x_true, y_pred, '-', label='Predicted')\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Time to refactor that?\n",
      "\n",
      "Yes, if we are going to keep experimenting with it.  But perhaps we will be moving on a little bit."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# describing the contents of a tree, with recursion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the next line is a tricky little trick to get some tab-completion help\n",
      "t = dt.tree_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_tree(t, root=0, depth=0):\n",
      "    indent = '    '*depth\n",
      "    \n",
      "    left_child = t.children_left[root]\n",
      "    right_child = t.children_right[root]\n",
      "    \n",
      "    if left_child == sklearn.tree._tree.TREE_LEAF:\n",
      "        print indent + 'return %.2f # (node %d)' % (t.value[root], root)\n",
      "    else:\n",
      "        print indent + 'if X_i[%d] < %.2f: # (node %d)' % (t.feature[root], t.threshold[root], root)\n",
      "        print_tree(t, root=________________________, depth=________________________)\n",
      "        \n",
      "        print indent + 'else:'\n",
      "        print_tree(t,root=________________________, depth=________________________)\n",
      "    \n",
      "print_tree(dt.tree_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Can you draw a tree version of that?\n",
      "\n",
      "## Is it right?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# pruning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a copy of the decision tree regressor dt (called pt, \"p\" for pruned)\n",
      "pt = sklearn.tree.DecisionTreeRegressor(min_samples_leaf=10)\n",
      "pt.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# have a look at node 12\n",
      "pt.tree_.value[12]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# need to set value at soon-to-be leaf node\n",
      "pt.tree_.value[12] = 1  # NOTE: this is not the right value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the left and right children of node 12\n",
      "left_child = pt.tree_.______________________[12]\n",
      "right_child = pt.tree_.______________________[12]\n",
      "\n",
      "# find the weight of these nodes in the training dataset\n",
      "wt_left = pt.tree_.______________________[left_child]\n",
      "wt_right = pt.tree_.______________________[right_child]\n",
      "\n",
      "# find the value of these nodes in the training dataset\n",
      "val_left = pt.tree_.______________________[left_child]\n",
      "val_right = pt.tree_.______________________[right_child]\n",
      "\n",
      "# calculate the value of node 12 after pruning\n",
      "pt.tree_.value[12] = (wt_left*val_left + wt_right*val_right) / (wt_left + wt_right)\n",
      "\n",
      "\n",
      "pt.tree_.children_left[12] = sklearn.tree._tree.TREE_LEAF\n",
      "pt.tree_.children_right[12] = sklearn.tree._tree.TREE_LEAF\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# have a look at the original tree compared to the pruned version\n",
      "y_pred = dt.predict(X_true)\n",
      "plt.plot(x_true, y_pred, '-', label='Original Pred')\n",
      "\n",
      "y_pred = pt.predict(X_true)\n",
      "plt.plot(x_true, y_pred, '-', label='Pruned Pred')\n",
      "\n",
      "#plt.plot(x_train, y_train, 's', label='Train')\n",
      "\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Another look at bounded-depth\n",
      "\n",
      "We will use our skills from last week's class to sweep over a range of depth values, and see which is best"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_vals = [1,2,4,8,16]\n",
      "\n",
      "# initialize rmse dict\n",
      "rmse = {}\n",
      "for d in d_vals:\n",
      "    rmse[d] = []\n",
      "\n",
      "# 10 repetitions of 10-fold cross-validation\n",
      "cv = sklearn.cross_validation.KFold(_____________________, _____________________)\n",
      "for rep in range(10):\n",
      "    for train, validate in cv:\n",
      "        for d in d_vals:\n",
      "            dt = sklearn.tree.DecisionTreeRegressor(max_depth=d)\n",
      "            dt.fit(X_train[train], y_train[train])\n",
      "\n",
      "            y_pred = dt.predict(X_train[validate])\n",
      "\n",
      "            rmse[k].append(np.sqrt(np.mean((y_pred - y_train[validate])**2)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(rmse)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(rmse).mean().plot(marker='s')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = sklearn.tree.DecisionTreeRegressor(max_depth=4)\n",
      "dt.fit(X_train, y_train)\n",
      "print_tree(dt.tree_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = sklearn.tree.DecisionTreeRegressor(max_depth=2)\n",
      "dt.fit(X_train, y_train)\n",
      "print_tree(dt.tree_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An aside: bootstrap + decision trees = good"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = sklearn.tree.DecisionTreeRegressor(max_depth=4)\n",
      "\n",
      "y_pred = {}\n",
      "for rep in range(500):\n",
      "    train = np.random.choice(range(len(y_train)), size=len(y_train))\n",
      "    \n",
      "    dt.fit(X_train[train], y_train[train])\n",
      "    y_pred[rep] = dt.predict(X_true)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = pd.DataFrame(y_pred)\n",
      "y_pred = y_pred.mean(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x_true, y_true, '-', label='Truth')\n",
      "plt.plot(x_train, y_train, 's', label='Train')\n",
      "plt.plot(x_true, y_pred, label='Mean of Bootstrapped Prediction')\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# One missing piece: measuring split quality"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here are the criteria for regression tree quality that sklearn knows\n",
      "sklearn.tree.tree.CRITERIA_REG"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here is a super-tricky way to modify the print_tree function\n",
      "# so that is includes the impurity\n",
      "\n",
      "# can you understand how it works?\n",
      "\n",
      "old_print_tree = print_tree\n",
      "\n",
      "def print_tree(t, root=0, depth=0):\n",
      "    indent = '    '*depth\n",
      "    print indent + '# node %d: impurity = %.2f' % (root, t.impurity[root])\n",
      "\n",
      "    old_print_tree(t, root, depth)\n",
      "    \n",
      "print_tree(dt.tree_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here is a less-tricky way to do the same thing\n",
      "# still tricky, since it uses recursion\n",
      "\n",
      "def print_tree(t, root=0, depth=0):\n",
      "    indent = '    '*depth\n",
      "    print indent + '# node %d: impurity = %.2f' % (root, t.impurity[root])\n",
      "    left_child = t.children_left[root]\n",
      "    right_child = t.children_right[root]\n",
      "    \n",
      "    if left_child == sklearn.tree._tree.TREE_LEAF:\n",
      "        print indent + 'return %.2f # (node %d)' % (t.value[root], root)\n",
      "    else:\n",
      "        print indent + 'if X_i[%d] < %.2f: # (node %d)' % (t.feature[root], t.threshold[root], root)\n",
      "        print_tree(t, root=left_child, depth=depth+1)\n",
      "        \n",
      "        print indent + 'else:'\n",
      "        print_tree(t,root=right_child, depth=depth+1)\n",
      "    \n",
      "print_tree(dt.tree_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mean squared error (MSE) criteria is realitively straight-forward:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt.criterion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean((y_train - y_train.mean())**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.var(y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternatives: mean absolute deviation, median absolute deviation, (something specific to your regression situation?)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# So far, we've looked entirely at DT regression, because it is prettier.\n",
      "\n",
      "In Week 4 homework, we has a DT classification problem.  How did it work?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here are the criteria that sklearn knows for classification problems\n",
      "sklearn.tree.tree.CRITERIA_CLF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which did you use in Homework 4?  Does using the other one change anything?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Some people say that a strength of Decision Trees (and hence Random Forests) is that there is no need to transform your variables.\n",
      "\n",
      "Show that this is correct for categorial labels (classification setting):\n",
      "\n",
      "Show that transforming variables _is_ relevant when labels are numeric (regression setting):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# A systematic approach to pruning\n",
      "\n",
      "One proposed approach to limiting the complexity of decision trees is through pruning to minimize the sum\n",
      "$$\n",
      "\\sum_{m=1}^{|T|} \\sum_{i: x_i \\in R_m} (y_i - \\hat{y}_{R_m})^2 + \\alpha |T|. \n",
      "$$\n",
      "\n",
      "This can be accomplished recursively: for a tree with a root and two leaves, you must determine if the MSE for the root is less than the MSE for the leaves + $\\alpha$.  For a more complicated tree, i.e. a root with two non-leaf subtrees, do the pruning separately for each subtree, and then see if you end up in the root-and-two-leave case.\n",
      "\n",
      "Super-hard extra bonus homework: implement this, and used cross-validation to see what it changes in the Exercise 4 example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}