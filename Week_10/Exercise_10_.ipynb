{
 "metadata": {
  "name": "",
  "signature": "sha256:511e57963a0f7ab77d4ea273b27479fd21d5d68f7f32c621bcd9812518cc6767"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!date\n",
      "import numpy as np, matplotlib.pyplot as plt, pandas as pd, seaborn as sns\n",
      "%matplotlib inline\n",
      "sns.set_context('talk')\n",
      "sns.set_style('darkgrid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sun Mar  8 16:31:09 PDT 2015\r\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As an example of the ensemble methods, I wil do an simpliefied version of Max's project, since I love it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -hal /home/j/Project/IRH/DEX/USA/EXPLORATORY/ML_Injury/CMS_SNF_complete.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw---- 1 mlbirger Domain Users 21M Mar  1 15:06 /home/j/Project/IRH/DEX/USA/EXPLORATORY/ML_Injury/CMS_SNF_complete.csv\r\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('/home/j/Project/IRH/DEX/USA/EXPLORATORY/ML_Injury/CMS_SNF_complete.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "(145644, 59)"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>year</th>\n",
        "      <th>age</th>\n",
        "      <th>sex</th>\n",
        "      <th>acause</th>\n",
        "      <th>ecode</th>\n",
        "      <th>i_N11</th>\n",
        "      <th>i_N12</th>\n",
        "      <th>i_N13</th>\n",
        "      <th>i_N14</th>\n",
        "      <th>i_N15</th>\n",
        "      <th>...</th>\n",
        "      <th>i_N5</th>\n",
        "      <th>i_N35</th>\n",
        "      <th>i_N6</th>\n",
        "      <th>i_N2</th>\n",
        "      <th>metric_vol_counts1</th>\n",
        "      <th>metric_vol_beddays1</th>\n",
        "      <th>metric_vol_mdcr_days1</th>\n",
        "      <th>metric_exp_mdcr_payments1</th>\n",
        "      <th>metric_exp_nonmdcr_payments1</th>\n",
        "      <th>metric_exp_charges1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1999</td>\n",
        "      <td> 40</td>\n",
        "      <td> 2</td>\n",
        "      <td> inj_animal</td>\n",
        "      <td> E9064</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0.00000</td>\n",
        "      <td> 0</td>\n",
        "      <td>    0.00000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1999</td>\n",
        "      <td> 65</td>\n",
        "      <td> 1</td>\n",
        "      <td> inj_animal</td>\n",
        "      <td> E9068</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 495.08209</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3693.00610</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1999</td>\n",
        "      <td> 70</td>\n",
        "      <td> 1</td>\n",
        "      <td> inj_animal</td>\n",
        "      <td> E9068</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0.00000</td>\n",
        "      <td> 0</td>\n",
        "      <td>    0.00000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1999</td>\n",
        "      <td> 70</td>\n",
        "      <td> 2</td>\n",
        "      <td> inj_animal</td>\n",
        "      <td> E9069</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0.00000</td>\n",
        "      <td> 0</td>\n",
        "      <td>    0.00000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1999</td>\n",
        "      <td> 75</td>\n",
        "      <td> 1</td>\n",
        "      <td> inj_animal</td>\n",
        "      <td> E9065</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 725.15808</td>\n",
        "      <td> 0</td>\n",
        "      <td>  467.14902</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 59 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "   year  age  sex      acause  ecode  i_N11  i_N12  i_N13  i_N14  i_N15  \\\n",
        "0  1999   40    2  inj_animal  E9064      0      0      0      0      0   \n",
        "1  1999   65    1  inj_animal  E9068      0      0      0      0      0   \n",
        "2  1999   70    1  inj_animal  E9068      0      0      0      0      0   \n",
        "3  1999   70    2  inj_animal  E9069      0      0      0      0      0   \n",
        "4  1999   75    1  inj_animal  E9065      0      0      0      0      1   \n",
        "\n",
        "          ...           i_N5  i_N35  i_N6  i_N2  metric_vol_counts1  \\\n",
        "0         ...              0      0     0     0                   0   \n",
        "1         ...              0      0     0     0                   2   \n",
        "2         ...              0      0     0     0                   0   \n",
        "3         ...              0      0     0     0                   0   \n",
        "4         ...              0      0     0     0                   2   \n",
        "\n",
        "   metric_vol_beddays1  metric_vol_mdcr_days1  metric_exp_mdcr_payments1  \\\n",
        "0                    0                      0                    0.00000   \n",
        "1                    2                      2                  495.08209   \n",
        "2                    0                      0                    0.00000   \n",
        "3                    0                      0                    0.00000   \n",
        "4                    2                      2                  725.15808   \n",
        "\n",
        "   metric_exp_nonmdcr_payments1  metric_exp_charges1  \n",
        "0                             0              0.00000  \n",
        "1                             0           3693.00610  \n",
        "2                             0              0.00000  \n",
        "3                             0              0.00000  \n",
        "4                             0            467.14902  \n",
        "\n",
        "[5 rows x 59 columns]"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.acause.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "inj_falls          88354\n",
        "inj_trans_other    25966\n",
        "inj_medical        22296\n",
        "inj_trans_road      3770\n",
        "inj_othunintent     1430\n",
        "inj_mech             835\n",
        "inj_poisoning        689\n",
        "inj_fires            580\n",
        "inj_foreign          462\n",
        "inj_animal           336\n",
        "inj_suicide          285\n",
        "mental_drug          257\n",
        "inj_homicide         186\n",
        "inj_disaster         165\n",
        "inj_war               27\n",
        "inj_drowning           4\n",
        "mental_alcohol         2\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for a stripped down version of Max's project, let's try to predict if an injury was caused by a fall\n",
      "y = np.array(df.acause == 'inj_falls')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# as predictors, we will use the year, age, sex, and indicators for all N-codes\n",
      "i_cols = df.filter(like='i_N').columns\n",
      "\n",
      "X = np.array(df.filter(['year', 'age', 'sex'] + list(i_cols)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is a nice, big dataset\n",
      "X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "((145644, 51), (145644,))"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set random seed for reproducibility\n",
      "np.random.seed(123456)\n",
      "\n",
      "# resample X and y to have equal number of examples from both classes\n",
      "i_true, = np.where(y == True)\n",
      "i_false, = np.where(y == False)\n",
      "\n",
      "# n=1000 positive and negative examples should run quickly for class\n",
      "n=10*1000\n",
      "i_resample = list(np.random.choice(i_true, size=n)) + list(np.random.choice(i_false, size=n))\n",
      "X = X[i_resample]\n",
      "y = y[i_resample]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# class frequencies\n",
      "np.unique(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 150,
       "text": [
        "array([False,  True], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# so a baseline classifier of always saying False has accuracy of\n",
      "np.mean(y == False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# How does logistic regression do?\n",
      "import sklearn.linear_model, sklearn.cross_validation\n",
      "c1 = sklearn.linear_model.LogisticRegression()\n",
      "\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c1, X, y, cv=cv, ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.1 s, sys: 0 ns, total: 1.1 s\n",
        "Wall time: 1.1 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "0.69510000000000005"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not too bad, but can we do better?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I would try Naive Bayes for this, and might as well do decision trees, too\n",
      "# How does logistic regression do?\n",
      "import sklearn.naive_bayes, sklearn.tree\n",
      "\n",
      "c2 = sklearn.naive_bayes.BernoulliNB()\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c2, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 390 ms, sys: 0 ns, total: 390 ms\n",
        "Wall time: 390 ms\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "0.69779999999999998"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c3 = sklearn.tree.DecisionTreeClassifier()\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c3, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 930 ms, sys: 0 ns, total: 930 ms\n",
        "Wall time: 931 ms\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "0.8516999999999999"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Will we be able to do any better with our fancy ensemble models?  I sure hope so!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Bagging\n",
      "\n",
      "    This algorithm encompasses several works from the literature. When random\n",
      "    subsets of the dataset are drawn as random subsets of the samples, then\n",
      "    this algorithm is known as Pasting [1]_. If samples are drawn with\n",
      "    replacement, then the method is known as Bagging [2]_. When random subsets\n",
      "    of the dataset are drawn as random subsets of the features, then the method\n",
      "    is known as Random Subspaces [3]_. Finally, when base estimators are built\n",
      "    on subsets of both samples and features, then the method is known as\n",
      "    Random Patches [4]_.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.ensemble\n",
      "c4 = sklearn.ensemble.BaggingClassifier()\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c4, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 9.4 s, sys: 0 ns, total: 9.4 s\n",
        "Wall time: 9.41 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "0.85214999999999996"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test your understanding: what happens if you Bag with Logistic Regression?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.BaggingClassifier(base_estimator=sklearn.linear_model.LogisticRegression())\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.11 s, sys: 0 ns, total: 1.11 s\n",
        "Wall time: 1.11 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "0.68400000000000016"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What about with \"decision stumps\" (aka one-R)?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.BaggingClassifier(base_estimator=sklearn.tree.DecisionTreeClassifier(max_depth=1))\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 254 ms, sys: 15 \u00b5s, total: 254 ms\n",
        "Wall time: 253 ms\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "0.64549999999999996"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Subspaces"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c5 = sklearn.ensemble.BaggingClassifier(max_samples=1., bootstrap=False, max_features=10)\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c5, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 168 ms, sys: 0 ns, total: 168 ms\n",
        "Wall time: 168 ms\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "0.68800000000000006"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Patches"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c5 = sklearn.ensemble.BaggingClassifier(max_samples=.1, bootstrap=True, max_features=10)\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c5, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 115 ms, sys: 3.99 ms, total: 119 ms\n",
        "Wall time: 118 ms\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "0.63400000000000001"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Random Forests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.ensemble\n",
      "c10 = sklearn.ensemble.RandomForestClassifier()\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c10, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.53 s, sys: 0 ns, total: 1.53 s\n",
        "Wall time: 1.53 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "0.85099999999999998"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c11 = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c11, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 12.4 s, sys: 0 ns, total: 12.4 s\n",
        "Wall time: 12.4 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "0.85220000000000007"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Boosting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c20 = sklearn.ensemble.AdaBoostClassifier()\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c20, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 7.77 s, sys: 0 ns, total: 7.77 s\n",
        "Wall time: 7.77 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "0.71784999999999988"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This approach was developed with things like decision stumps in mind:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.AdaBoostClassifier(base_estimator=sklearn.tree.DecisionTreeClassifier(max_depth=1))\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 7.77 s, sys: 0 ns, total: 7.77 s\n",
        "Wall time: 7.77 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "0.71784999999999988"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.AdaBoostClassifier(base_estimator=sklearn.tree.DecisionTreeClassifier(max_depth=2))\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 12.4 s, sys: 0 ns, total: 12.4 s\n",
        "Wall time: 12.4 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "0.75209999999999988"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.AdaBoostClassifier(base_estimator=sklearn.tree.DecisionTreeClassifier(max_depth=3))\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 18 s, sys: 0 ns, total: 18 s\n",
        "Wall time: 18 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "0.78915000000000002"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gradient Boosting is beloved by some, although I have not had life-changing success with it, myself:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c21 = sklearn.ensemble.GradientBoostingClassifier()\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c21, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 22 s, sys: 0 ns, total: 22 s\n",
        "Wall time: 22 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "0.74009999999999998"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.GradientBoostingClassifier(max_depth=4)\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = sklearn.ensemble.GradientBoostingClassifier(max_depth=5)\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True, random_state=123456)\n",
      "%time np.mean(sklearn.cross_validation.cross_val_score(c, X, y, cv=cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Stacking"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From http://nbviewer.ipython.org/github/cse40647/cse40647/blob/sp.14/32%20-%20Stacking%20&%20Blending.ipynb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (c) 2014 Reid Johnson\n",
      "#\n",
      "# Modified from:\n",
      "# Kemal Eren (https://github.com/kemaleren/scikit-learn/blob/stacking/sklearn/ensemble/stacking.py)\n",
      "#\n",
      "# Generates a stacking/blending of base models. Cross-validation is used to \n",
      "# generate predictions from base (level-0) models that are used as input to a \n",
      "# combiner (level-1) model.\n",
      "\n",
      "import numpy as np\n",
      "from itertools import izip\n",
      "from sklearn.base import ClassifierMixin, RegressorMixin\n",
      "from sklearn.ensemble.base import BaseEnsemble\n",
      "from sklearn.utils.validation import assert_all_finite\n",
      "\n",
      "\n",
      "class Stacking(BaseEnsemble):\n",
      "    \"\"\"Implements stacking/blending.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    meta_estimator : string or callable\n",
      "        May be one of \"best\", \"vote\", \"average\", or any classifier or \n",
      "        regressor constructor\n",
      "\n",
      "    estimators : iterator\n",
      "        An iterable of estimators; each must support predict_proba()\n",
      "\n",
      "    cv : iterator\n",
      "        A cross validation object. Base (level-0) estimators are trained on \n",
      "        the training folds, then the meta (level-1) estimator is trained on \n",
      "        the testing folds.\n",
      "\n",
      "    stackingc : bool\n",
      "        Whether to use StackingC or not. For more information, refer to the \n",
      "        following paper:\n",
      "\n",
      "        Reference:\n",
      "          A. K. Seewald, \"How to Make Stacking Better and Faster While Also \n",
      "          Taking Care of an Unknown Weakness,\" 2002.\n",
      "\n",
      "    kwargs :\n",
      "        Arguments passed to instantiate meta_estimator.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] D. H. Wolpert, \"Stacked Generalization\", 1992.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # TODO: Support different features for each estimator.\n",
      "    # TODO: Support \"best\", \"vote\", and \"average\" for already trained model.\n",
      "    # TODO: Allow saving of estimators, so they need not be retrained when \n",
      "    #       trying new stacking methods.\n",
      "\n",
      "    def __init__(self, meta_estimator, estimators,\n",
      "                 cv, stackingc=True, proba=True,\n",
      "                 **kwargs):\n",
      "        self.estimators_ = estimators\n",
      "        self.n_estimators_ = len(estimators)\n",
      "        self.cv_ = cv\n",
      "        self.stackingc_ = stackingc\n",
      "        self.proba_ = proba\n",
      "\n",
      "        if stackingc:\n",
      "            if isinstance(meta_estimator, str) or not issubclass(meta_estimator, RegressorMixin):\n",
      "                raise Exception('StackingC only works with a regressor.')\n",
      "\n",
      "        if isinstance(meta_estimator, str):\n",
      "            if meta_estimator not in ('best',\n",
      "                                      'average',\n",
      "                                      'vote'):\n",
      "                raise Exception('Invalid meta estimator: {0}'.format(meta_estimator))\n",
      "            raise Exception('\"{0}\" meta estimator not implemented'.format(meta_estimator))\n",
      "        elif issubclass(meta_estimator, ClassifierMixin):\n",
      "            self.meta_estimator_ = meta_estimator(**kwargs)\n",
      "        elif issubclass(meta_estimator, RegressorMixin):\n",
      "            self.meta_estimator_ = MRLR(meta_estimator, stackingc, **kwargs)\n",
      "        else:\n",
      "            raise Exception('Invalid meta estimator: {0}'.format(meta_estimator))\n",
      "\n",
      "    def _base_estimator_predict(self, e, X):\n",
      "        \"\"\"Predict label values with the specified estimator on predictor(s) X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        e : int\n",
      "            The estimator object.\n",
      "\n",
      "        X : np.ndarray, shape=(n, m)\n",
      "            The feature data for which to compute the predicted outputs.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        pred : np.ndarray, shape=(len(X), 1)\n",
      "            The mean of the label probabilities predicted by the specified \n",
      "            estimator for each fold for each instance X.\n",
      "        \"\"\"\n",
      "        # Generate array for the base-level testing set, which is n x n_folds.\n",
      "        pred = e.predict(X)\n",
      "        assert_all_finite(pred)\n",
      "        return pred\n",
      "\n",
      "    def _base_estimator_predict_proba(self, e, X):\n",
      "        \"\"\"Predict label probabilities with the specified estimator on \n",
      "        predictor(s) X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        e : int\n",
      "            The estimator object.\n",
      "\n",
      "        X : np.ndarray, shape=(n, m)\n",
      "            The feature data for which to compute the predicted outputs.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        pred : np.ndarray, shape=(len(X), 1)\n",
      "            The mean of the label probabilities predicted by the specified \n",
      "            estimator for each fold for each instance X.\n",
      "        \"\"\"\n",
      "        # Generate array for the base-level testing set, which is n x n_folds.\n",
      "        pred = e.predict_proba(X)\n",
      "        assert_all_finite(pred)\n",
      "        return pred\n",
      "\n",
      "    def _make_meta(self, X):\n",
      "        \"\"\"Make the feature set for the meta (level-1) estimator.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : np.ndarray, shape=(n, m)\n",
      "            The feature data.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        An n x len(self.estimators_) array of meta-level features.\n",
      "        \"\"\"\n",
      "        rows = []\n",
      "        for e in self.estimators_:\n",
      "            if self.proba_:\n",
      "                # Predict label probabilities\n",
      "                pred = self._base_estimator_predict_proba(e, X)\n",
      "            else:\n",
      "                # Predict label values\n",
      "                pred = self._base_estimator_predict(e, X)\n",
      "            rows.append(pred)\n",
      "        return np.hstack(rows)\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        \"\"\"Fit the estimator given predictor(s) X and target y.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : np.ndarray, shape=(n, m)\n",
      "            The feature data on which to fit.\n",
      "\n",
      "        y : array of shape = [n_samples]\n",
      "            The actual outputs (class data).\n",
      "        \"\"\"\n",
      "        # Build meta data.\n",
      "        X_meta = [] # meta-level features\n",
      "        y_meta = [] # meta-level labels\n",
      "\n",
      "        print 'Training and validating the base (level-0) estimator(s)...'\n",
      "        print\n",
      "        for i, (a, b) in enumerate(self.cv_):\n",
      "            print 'Fold [%s]' % (i)\n",
      "\n",
      "            X_a, X_b = X[a], X[b] # training and validation features\n",
      "            y_a, y_b = y[a], y[b] # training and validation labels\n",
      "\n",
      "            # Fit each base estimator using the training set for the fold.\n",
      "            for j, e in enumerate(self.estimators_):\n",
      "                print '  Training base (level-0) estimator %d...' % (j),\n",
      "                e.fit(X_a, y_a)\n",
      "                print 'done.'\n",
      "\n",
      "            proba = self._make_meta(X_b)\n",
      "            X_meta.append(proba)\n",
      "            y_meta.append(y_b)\n",
      "        print\n",
      "\n",
      "        X_meta = np.vstack(X_meta)\n",
      "        if y_meta[0].ndim == 1:\n",
      "            y_meta = np.hstack(y_meta)\n",
      "        else:\n",
      "            y_meta = np.vstack(y_meta)\n",
      "\n",
      "        # Train meta estimator.\n",
      "        print 'Training meta (level-1) estimator...',\n",
      "        self.meta_estimator_.fit(X_meta, y_meta)\n",
      "        print 'done.'\n",
      "\n",
      "        # Re-train base estimators on full data.\n",
      "        for j, e in enumerate(self.estimators_):\n",
      "            print 'Re-training base (level-0) estimator %d on full data...' % (j),\n",
      "            e.fit(X, y)\n",
      "            print 'done.'\n",
      "\n",
      "    def predict(self, X):\n",
      "        \"\"\"Predict label values with the fitted estimator on predictor(s) X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : np.ndarray, shape=(n, m)\n",
      "            The feature data for which to compute the predicted output.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        array of shape = [n_samples]\n",
      "            The predicted label values of the input samples.\n",
      "        \"\"\"\n",
      "        X_meta = self._make_meta(X)\n",
      "        return self.meta_estimator_.predict(X_meta)\n",
      "\n",
      "    def predict_proba(self, X):\n",
      "        \"\"\"Predict label probabilities with the fitted estimator on \n",
      "        predictor(s) X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : np.ndarray, shape=(n, m)\n",
      "            The feature data for which to compute the predicted output.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        array of shape = [n_samples]\n",
      "            The predicted label probabilities of the input samples.\n",
      "        \"\"\"\n",
      "        X_meta = self._make_meta(X)\n",
      "        return self.meta_estimator_.predict_proba(X_meta)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "clfs = [c1, c2, c3, c4, c5, c10, c11, c20, c21]\n",
      "\n",
      "# Generate k stratified folds of the training data.\n",
      "cv = sklearn.cross_validation.StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=123456)\n",
      "skf = list(cv)  # do you know what this does?  turns an iterator into a list (of lists)... tricky!\n",
      "\n",
      "stk = Stacking(sklearn.linear_model.LogisticRegression, clfs, skf, stackingc=False, proba=True)\n",
      "stk.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.metrics.accuracy_score(y_test, stk.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How much data did we use?  try it with more, 10,000 for each class... or 100,000."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    }
   ],
   "metadata": {}
  }
 ]
}