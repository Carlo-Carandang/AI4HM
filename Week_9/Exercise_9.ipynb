{
 "metadata": {
  "name": "",
  "signature": "sha256:eeea73446f4b4748aed8da0efc602ebc51dd082a8b6f16505ba7cd5b3d3bc53d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!date\n",
      "import numpy as np, matplotlib.pyplot as plt, pandas as pd, seaborn as sns\n",
      "%matplotlib inline\n",
      "sns.set_context('talk')\n",
      "sns.set_style('darkgrid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set random seed for reproducibility\n",
      "np.random.seed(12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Attribute Selection\n",
      "\n",
      "Remember our good, old, noisy sinewave?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_true = np.linspace(0,4,1000)\n",
      "y_true = np.sin(x_true)\n",
      "\n",
      "obs = np.random.choice(range(1000), size=100, replace=False)\n",
      "x_obs = x_true[obs]\n",
      "y_obs = np.random.normal(y_true[obs], .3)\n",
      "\n",
      "plt.plot(x_true, y_true, label='True')\n",
      "plt.plot(x_obs, y_obs, 's', label='Observed')\n",
      "plt.legend(loc=(1,.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And here are a few ways to fit this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.linear_model, sklearn.svm, sklearn.ensemble"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m1 = sklearn.linear_model.LinearRegression()\n",
      "m2 = sklearn.svm.SVR()\n",
      "m3 = sklearn.ensemble.RandomForestRegressor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = x_obs[:,None]\n",
      "y = y_obs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m1.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m2.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m3.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_pred(m,label):\n",
      "    X = x_true[:,None]\n",
      "    y = m.predict(X)\n",
      "    plt.plot(X, y, label=label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What do you think the predictions from m1, m2, and m3 are going to look like?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x_true, y_true, label='True')\n",
      "plt.plot(x_obs, y_obs, 's', label='Observed')\n",
      "\n",
      "# plot_pred(m1, 'Linear Regression')\n",
      "# plot_pred(m2, 'SVM')\n",
      "# plot_pred(m3, 'Random Forest')\n",
      "\n",
      "plt.legend(loc=(1,.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add random noise as a predictor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.hstack((X, np.random.normal(size=(100,1))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m1.fit(X,y)\n",
      "m2.fit(X,y)\n",
      "m3.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_pred_w_noise(m,label):\n",
      "    X = x_true[:,None]\n",
      "    X = np.hstack((X, np.random.normal(size=(1000,1))))\n",
      "    y = m.predict(X)\n",
      "    plt.plot(X[:,0], y, label=label, alpha=.75)\n",
      "    \n",
      "plt.plot(x_true, y_true, label='True')\n",
      "plt.plot(x_obs, y_obs, 's', label='Observed')\n",
      "\n",
      "plot_pred_w_noise(m1, 'Linear Regression')\n",
      "plot_pred_w_noise(m2, 'SVM')\n",
      "plot_pred_w_noise(m3, 'Random Forest')\n",
      "\n",
      "plt.legend(loc=(1,.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Work through one round of forward selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = x_obs[:,None]\n",
      "y = y_obs\n",
      "X = np.hstack((X, np.random.normal(size=(100,10))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how does forward selection determine which column of X to include first?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Work through one round of backwards elimination"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = x_obs[:,None]\n",
      "y = y_obs\n",
      "X = np.hstack((X, np.random.normal(size=(100,10))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how does backwards elimination determine which column of X to remove first?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you need to use this in your project, consider learning more about the backwards elimination method in sklearn with `sklearn.feature_selection.RFE` and `.RFECV`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.feature_selection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = sklearn.feature_selection.RFE(sklearn.linear_model.LinearRegression(), n_features_to_select=2, step=1)\n",
      "r.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# features included\n",
      "r.support_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Discretization\n",
      "\n",
      "An example from Verbal Autopsy: symptom duration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load va data from Week 4\n",
      "df = pd.read_csv('../Week_4/IHME_PHMRC_VA_DATA_ADULT_Y2013M09D11_0.csv', low_memory=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to look at questions about the cough symptom here: a2_32 and a2_33"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# did deceased have cough?\n",
      "df.a2_32.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tabulate that: did deceased have cough?\n",
      "df.a2_32.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# how long did the cough last (in days)?\n",
      "df.a2_33.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.distplot(np.log(df.a2_33+1))\n",
      "plt.xlabel('log(duration+1)')\n",
      "plt.ylabel('probability density')\n",
      "plt.axis(xmin=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# it is getting annoying to remember that silly name...\n",
      "df['cough'] = df.a2_32 == 'Yes'\n",
      "df['duration'] = df.a2_33.map(float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.cough].duration.describe(percentiles=[.025,.25,.50,.75,.975])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Duration ranges from 0 to 14400 days.\n",
      "\n",
      "Now: discretize duration variable into $K$ equal width bins, for $K = \\sqrt{2766}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is \"fixed width\" discretization, hence the name fw_disc:\n",
      "df['fw_disc_duration'] = ________________________________"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And how do you make this discretized covariate something suitable for binary classifiers?  One-Hot encoding, of course."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for val in df.fw_disc_duration.unique():\n",
      "    df['duration_in_bin_%d'%val] = (df.fw_disc_duration == val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or Thermometer encoding:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for val in df.fw_disc_duration.unique():\n",
      "    df['duration_in_bin_at_least_%d'%val] = ___________________________________"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How about fixed frequency discretization?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ordered_durations = np.array(df[df.cough].duration.order())\n",
      "ordered_durations[np.linspace(0,2766,52, endpoint=False).astype(int)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['ff_disc_duration'] = _________________________________"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What we ended up doing is looking at the mean duration stratified by cause:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.groupby('gs_text34').duration.mean().order(ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.distplot(df.groupby('gs_text34').duration.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['cough_duration_is_long'] = (df.duration > ____________________)\n",
      "df['cough_duration_is_really_long'] = (df.duration > ______________________________)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Projections\n",
      "\n",
      "Not too much more to say, since a lot of last week was really on this.  You've got PCA, MDS, Factor Analysis, and Random Tree Encodings in your Exercise 8 notebook, if you need any of that fancy stuff.\n",
      "\n",
      "If you need partial least squares regression in sklearn, you can find it here:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.cross_decomposition\n",
      "\n",
      "m4 = sklearn.cross_decomposition.PLSRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So for our exercise, just two little examples of \"semantic projections\".\n",
      "\n",
      "One from VA, wherein dates can be subtracted to make a more meaningful feature:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# year of birth\n",
      "df.g1_01y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# year of death\n",
      "df.g1_06y.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much more meaningful to have the age of the deceased (which is `g1_07a` in the database, but let's pretend it is not)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_at_death = _________________________________\n",
      "age_at_death"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for use later:\n",
      "reported_age_at_death = df.g1_07a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another time this comes up: timeseries, like Ebola case counts:  http://institutefordiseasemodeling.github.io/EVD/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sampling\n",
      "\n",
      "Sample 1000 numbers from 0, 1, ..., 1e7, *with* replacement:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.choice(____________________________)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, *without* replacement:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.choice(______________________________)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Speed is a good reason to do this sort of sampling.  Let us revisit the noisy sinewave to see what I mean:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12345)\n",
      "\n",
      "x_true = np.linspace(0,4,1000)\n",
      "y_true = np.sin(x_true)\n",
      "\n",
      "x_obs = np.linspace(0,4,1000*1000)\n",
      "y_obs = np.random.normal(np.sin(x_obs), .3)\n",
      "\n",
      "plt.plot(x_obs, y_obs, ',', label='Observed', alpha=.5)\n",
      "plt.plot(x_true, y_true, label='True', linewidth=10)\n",
      "plt.legend(loc=(1,.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = sklearn.ensemble.RandomForestRegressor()\n",
      "%time m.fit(x_obs[:,None], y_obs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x_obs, y_obs, ',', label='Observed', alpha=.5)\n",
      "plot_pred(m, 'Random Forest')\n",
      "plt.plot(x_true, y_true, label='True', linewidth=4)\n",
      "plt.legend(loc=(1,.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = {}\n",
      "for n_sample in [10,50,100,500,1000,5000,10*1000,50*1000,100*1000]:\n",
      "    random_sample = np.random.choice(_____________________________)\n",
      "    \n",
      "    t[n_sample] = time.time()\n",
      "    %time m.fit(x_obs[random_sample,None], y_obs[random_sample])\n",
      "    t[n_sample] = time.time() - t[n_sample]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = pd.Series(t)\n",
      "plt.loglog(t.index, t, 's-')\n",
      "plt.ylabel('Time (seconds)')\n",
      "plt.xlabel('Rows of training data (n)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now what you should also do is have a look at the prediction accuracy as a function of number of samples, to decide how much data is worth your time.  (Evaluate out-of-sample, of course!)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Cleansing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How long is the index of the `age_at_death` series we made in our semantic projection part of the exercise?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(age_at_death.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And how much of it is missing?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_at_death.isnull().sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should fill it in somehow.  What does the non-missing part look like?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_at_death.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Negative ages are not good..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(reported_age_at_death.map(float_or_nan), age_at_death, 'o')\n",
      "plt.xlabel('Reported Age at Death (years)')\n",
      "plt.ylabel('Reported year of death minus year of birth')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cleaning this up a mess like this is something with which I suspect many of my students are familiar."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hidden in this section is a very interesting approach which DM calls \"generating artificial data\".  This is a way that you can use any supervised learning algorithm to do unsupervised work.  We will experiment with it with Nick's example data, and I hope he will push this further as part of his project:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('Nick_project_data_example_ZWE_2010_DHS_cleaned.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start with the feature vectors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_real = np.array(df.iloc[:, 1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Label it all as real:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n,p = X_real.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_real = np.array(['real']*n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then make fake data, which has the same univariate distributions, but none of the correlation structure:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_fake = np.empty((n,p))\n",
      "for j in range(p):\n",
      "    X_fake[:,j] = np.random.choice(____________________________________)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "label this as fake:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_fake = np.array(['fake']*n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Stick them together and you have the labeled examples for supervised learning:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.vstack((X_real, X_fake))\n",
      "y = np.hstack((y_real, y_fake))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_real.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_real.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c1 = sklearn.linear_model.LogisticRegression()\n",
      "c1.fit(X,y)\n",
      "c1.score(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c2 = sklearn.ensemble.RandomForestClassifier()\n",
      "c2.fit(X,y)\n",
      "c2.score(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(c2, X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So the question for Nick is, how does RF do it?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Transforming Multiple Classes to Binary Classes\n",
      "\n",
      "A sketch of the ways with the VA data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load va data from Week 4\n",
      "df = pd.read_csv('../Week_4/IHME_PHMRC_VA_DATA_ADULT_Y2013M09D11_0.csv', low_memory=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.gs_text34.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In \"one-vs-all\" approach, for each multiclass label, make a new problem of classifying as \"is it this label?\" "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = ____________________________"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In \"one-vs-one approach, for each pair of labels, make a new problem with instances just for that pair:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = ____________________________________\n",
      "y = df[rows].gs_text34"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Calibration\n",
      "\n",
      "Is anyone thinking about predicting probabilities for their projects at this point?  It can be very cool, but also hard.  Returning to the stuff from Nick's project:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.vstack((X_real, X_fake))\n",
      "y = np.hstack((y_real, y_fake))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = np.random.choice(range(len(X)), size=len(X)/2, replace=False)\n",
      "test = list(set(range(len(X))) - set(train))\n",
      "\n",
      "c = sklearn.ensemble.RandomForestClassifier()\n",
      "c.fit(X[train], y[train])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can make probability predictions for most classifiers in `sklearn`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.predict_proba(X[test[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Did that tend towards right answer?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y[test[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Can't tell from that, actually..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.classes_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So yes...  How does it do on things it say are 80% chance real, overall?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pr_pred = c.predict_proba(X[test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How many things like this are there?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_pr_pred[:,1]==.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# in general, better to have a little wiggle room\n",
      "np.sum((y_pr_pred[:,1] >= .79)&(y_pr_pred[:,1] < .81))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = np.where(y_pr_pred[:,1]==.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = np.array(test)\n",
      "np.mean(y[test[rows]] == 'real')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So this is a bit conservative!  What about for some low probability examples?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(y_pr_pred[:,1]==0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = np.where(y_pr_pred[:,1]==0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(y[test[rows]] == 'real')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perhaps with more trees, things would be better.  But Random Forests are not supposed to do probability prediction, so perhaps we need to work on it a little bit ourselves if this is what is desired.  Got any ideas for how to do so?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}